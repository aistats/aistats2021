---
layout: default
---

<script type="text/javascript">
    document.getElementById('LNschedule').id='leftcurrent';
</script>

<style type="text/css">
.schedule_table {
    margin-bottom: 2em;
}

.schedule_table th{
    border-top: 1px solid black;
    border-bottom: 1px solid black;

}
.schedule_table td{
    padding: 0.5em;
}

.schedule_table td:nth-child(1) {
    min-width: 80px;
    white-space: nowrap;
}


.schedule_table td:nth-child(2) {
    border-left: 1px solid black;
    border-bottom: 1px dashed black;
}

.schedule_table tr:last-child td{
    border-bottom: 1px solid black;

}

</style>

<div class="contents">

<h1>AISTATS 2016 Schedule</h1>

<!--<h3>Notice</h3>-->
<!--<UL>-->
<!--  <LI>Schedules in this page are tentative, subjec to change without prior notice.-->
<!--  <LI>Registration desk will be open 10:30 - 13:30, 15:00 - 17:00 on May 9, 10:00 - 12:00, 16:00 - 18:00 on May 10, and 10:00 - 12:00 on May 11. In case of emergency, please contact Karen Smith (aistats2015.ksmith at gmail.com).-->
<!--  </LI>-->
<!--</UL>-->

<br>

<h2>May 9 (Monday)</h2>
   <table class="schedule_table" cellspacing="0">
       <tr>
           <th>Time</th>
           <th>Schedule</th>
       </tr>

       <tr>
           <td>9:00 - 10:00</td>
           <td>Invited speaker: <a href="{{ site.baseurl }}/speakers.html#session1">Richard Samworth</a></td>
       </tr>
       <tr>
           <td>10:10 - 11:30</td>
           <td><u>Oral Session 1.1: Gaussian processes</u>
           
               <ul>
                   <!--302-->
               <li><b>GLASSES: Relieving The Myopia Of Bayesian Optimisation</b><br>
Javier Gonzalez, Michael Osborne, Neil Lawrence
               </li>
               <!--370-->
               <li><b> Optimization as Estimation with Gaussian Processes in Bandit Settings</b><br>
Zi Wang, Bolei Zhou, Stefanie Jegelka,
               </li>
               <!--76-->
               <li><b> Scalable Gaussian Process Classification via Expectation Propagation</b><br>
Daniel Hernandez-Lobato, Jose Miguel Hernandez-Lobato
               </li>
               <!--21-->
               <li><b> Control Functionals for Quasi-Monte Carlo Integration</b><br>
Chris Oates, Mark Girolami
               </li>
               </ul>
           </td>
       </tr>
       <tr>
           <td>11:30 - 14:00</td>
           <td><a href="{{ site.baseurl }}/poster_sessions.html#poster_session1">Poster session 1</a></td>
       </tr>
       <tr>
           <td>14:00 - 15:30</td>
           <td>Lunch (on your own)</td>
       </tr>
       <tr>
           <td>15:30 - 16:50</td>
           <td><u>Oral Session 1.2: Deep learning and reinforcement learning</u>

               <ul>
                   <!--147-->
                   <li><b> Dreaming More Data: Class-dependent Distributions over Diffeomorphisms for Learned Data Augmentation</b><br>
Søren Hauberg, Oren Freifeld, Anders Boesen Lindbo Larsen
                   </li>
                   <!--381-->
                   <li><b> Bridging the Gap between Stochastic Gradient MCMC and Stochastic Optimization</b><br>
Changyou Chen, David Carlson, Zhe Gan, Chunyuan Li, Lawrence Carin
                   </li>
                   <!--305-->
                   <li><b> Stochastic Neural Networks with Monotonic Activation Functions</b><br>
Siamak Ravanbakhsh, Barnabas Poczos, Jeff Schneider, Dale Schuurmans, Russell Greiner
                   </li>
                   <!--37-->
                   <li><b> Inverse Reinforcement Learning with Simultaneous Estimation of Rewards and Dynamics</b><br>
Michael Herman, Tobias Gindele, Jörg Wagner, Felix Schmitt, Wolfram Burgard
                   </li>
               </ul>
           </td>
       </tr>
       <tr>
           <td>16:50 - 17:20</td>
           <td>Coffee break</td>
       </tr>
       <tr>
           <td>17:20 - 18:40</td>
           <td><u>Oral Session 1.3: Monte Carlo methods for Bayesian inference</u>
               <ul>
                   <!--159-->
                   <li><b> K2-ABC: Approximate Bayesian Computation with Kernel Embeddings</b><br>
Mijung Park, Wittawat Jitkrittum, Dino Sejdinovic
                   </li>
                   <!--10-->
                   <li><b> C3: Lightweight Incrementalized MCMC for Probabilistic Programs using Continuations and Callsite Caching</b><br>
Daniel Ritchie, Andreas Stuhlmüller, Noah Goodman
                   </li>
                   <!--477-->
                   <li><b> Parallel Markov Chain Monte Carlo via Spectral Clustering</b><br>
Guillaume Basse, Aaron Smith, Natesh Pillai
                   </li>
                   <!--361-->
                   <li><b> Provable Bayesian Inference via Particle Mirror Descent</b><br>
Bo Dai, Niao He, Hanjun Dai, Le Song
                   </li>
            </ul>
           </td>
       </tr>
   </table>

<h2>May 10 (Tuesday)</h2>
   <table class="schedule_table" cellspacing="0">
       <tr>
           <th>Time</th>
           <th>Schedule</th>
       </tr>

       <tr>
           <td>9:00 - 10:00</td>
           <td>Invited speaker: <a href="{{ site.baseurl }}/speakers.html#session2">Kamalika Chaudhuri</a></td>
       </tr>
       <tr>
           <td>10:10 - 11:30</td>
           <td><u>Oral Session 2.1: Graphical models</u>
           
               <ul>
                   <!--106-->
                   <li><b> Survey Propagation beyond Constraint Satisfaction Problems</b><br>
Christopher Srinivasa, Siamak Ravanbakhsh, Brendan Frey
                   </li>
                   <!--13-->
                   <li><b> Tightness of LP Relaxations for Almost Balanced Models</b><br>
Adrian Weller, David Sontag
                   </li>
                   <!--495-->
                   <li><b> Active Learning Algorithms for Graphical Model Selection</b><br>
Gautamd Dasarathy, Aarti Singh, Maria-Florina Balcan, Jong Park
                   </li>
                   <!--390-->
                   <li><b> Tight Variational Bounds via Random Projections and I-Projections</b><br>
Lun-Kai Hsu, Tudor Achim, Stefano Ermon
                   </li>
               </ul>
           </td>
       </tr>
       <tr>
           <td>11:30 - 14:00</td>
           <td><a href="{{ site.baseurl }}/poster_sessions.html#poster_session2">Poster session 2</a></td>
       </tr>
       <tr>
           <td>14:00 - 15:30</td>
           <td>Lunch (on your own)</td>
       </tr>
       <tr>
           <td>15:30 - 16:50</td>
           <td><u>Oral Session 2.2: Theory of learning</u>
               <ul> 
                   <!--23-->
                   <li><b> Probability Inequalities for Kernel Embeddings in Sampling without Replacement</b><br>
Markus Schneider
                   </li>
                   <!--154-->
                   <li><b> Nearly optimal classification for semimetrics</b><br>
Lee-Ad Gottlieb, Aryeh Kontorovich, Pinhas Nisnevitch
                   </li>
                   <!--423-->
                   <li><b> Online learning with noisy side observations</b><br>
Tomáš Kocák, Gergely Neu, Michal Valko
                   </li>
                   <!--476-->
                   <li><b> Differentially Private Causal Inference</b><br>
Matt Kusner, Yu Sun, Karthik Sridharan, Kilian Weinberger
                   </li>
               </ul>
           </td>
       </tr>
       <tr>
           <td>16:50 - 17:20</td>
           <td>Coffee break</td>
       </tr>
       <tr>
           <td>17:20 - 18:40</td>
           <td><u>Oral Session 2.3: Matrix and tensor methods</u>
               <ul>
                   <!--526-->
                   <li><b> Multiresolution Matrix Compression</b><br>
Nedelina Teneva, Pramod Kaushik Mudrakarta, Risi Kondor
                   </li>
                   <!--212-->
                   <li><b> Low-Rank and Sparse Structure Pursuit via Alternating Minimization</b><br>
Quanquan Gu, Zhaoran Wang, Han Liu
                   </li>
                   <!--104-->
                   <li><b> Tensor vs Matrix Methods: Robust Tensor Decomposition under Block Sparse Perturbations</b><br>
Anima Anandkumar, Prateek Jain, Yang Shi, Niranjan Uma Naresh
                   </li>
                   <!--221-->
                   <li><b> Tractable and Scalable Schatten Quasi-Norm Approximations for Rank Minimization</b><br>
Fanhua Shang, Yuanyuan Liu, James Cheng
                   </li>
               </ul>
           </td>
       </tr>
   </table>

<h2>May 11 (Wednesday)</h2>
   <table class="schedule_table" cellspacing="0">
       <tr>
           <th>Time</th>
           <th>Schedule</th>
       </tr>

       <tr>
           <td>9:00 - 10:00</td>
           <td>Invited speaker: <a href="{{ site.baseurl }}/speakers.html#session3">Adam Tauman Kalai </a></td>
       </tr>
       <tr>
           <td>10:10 - 11:30</td>
           <td><u>Oral Session 3.1: Large-scale learning</u>
           
               <ul>
                   <!--190-->
                   <li><b> Large-Scale Semi-Supervised Learning Using Streaming Approximation</b><br>
Sujith Ravi, Qiming Diao
                   </li>
                   <!--374-->
                   <li><b> A Convex Surrogate Operator for General Non-Modular Loss Functions</b><br>
Jiaqian Yu, Matthew Blaschko
                   </li>
                   <!--346-->
                   <li><b> Ordered Weighted l1 Regularized Regression with Strongly Correlated Covariates: Theoretical Aspects</b><br>
Mario Figueiredo, Robert Nowak
                   </li>
                   <!--321-->
                   <li><b> Scalable geometric density estimation</b><br>
Ye Wang, Antonio Canale, David Dunson
                   </li>
               </ul>
           </td>
       </tr>
       <tr>
           <td>11:30 - 14:00 </td>
           <td><a href="{{ site.baseurl }}/poster_sessions.html#poster_session3">Poster session 3</a> and MLSS posters.</td>
       </tr>
       <tr>
           <td>14:00 - 15:30</td>
           <td>Lunch (on your own)</td>
       </tr>
       <tr>
           <td>15:30 - 16:50</td>
           <td><u>Oral Session 3.2: Sensing and Information</u>
               <ul>
                   <!--326-->
                   <li><b> DUAL-LOCO: Distributing Statistical Estimation Using Random Projections</b><br>
Christina Heinze, Brian McWilliams, Nicolai Meinshausen
                   </li>
                   <!--439-->
                   <li><b> Controlling Bias in Adaptive Data Analysis Using Information Theory</b><br>
Daniel Russo, James Zou
                   </li>
                   <!--148-->
                   <li><b> Unsupervised Ensemble Learning with Dependent Classifiers</b><br>
Ethan Fetaya 
                   </li>
                   <!--50-->
                   <li><b> Learning Sparse Additive Models with Interactions in High Dimensions</b><br>
Hemant Tyagi, Anastasios Kyrillidis, Bernd Gärtner, Andreas Krause
                   </li>
               </ul>
           </td>
       </tr>
       <tr>
           <td>16:50 - 17:20</td>
           <td>Coffee break</td>
       </tr>
       <tr>
           <td>17:20 - 18:40</td>
           <td><u>Oral Session 3.3: Variational methods and point processes</u>
           
               <ul>
                   <li><b> Early Stopping as Nonparametric Variational Inference</b><br>
David Duvenaud, Dougal Maclaurin, Ryan Adams
                   </li>
                   <li><b> Efficient Sampling for k-Determinantal Point Processes</b><br>
Chengtao Li, Stefanie Jegelka, Suvrit Sra
                   </li>
                   <li><b> Universal Models of Multivariate Temporal Point Processes</b><br>
Asela Gunawardana, Chris Meek
                   </li>
               </ul>

           </td>
       </tr>
   </table>

<br>


  <!--<table width="538" border="1" align="center" bgcolor="#FFFFFF">-->
  <!--  <tr>-->
  <!--    <th width="100" scope="col" bgcolor="#3fcccc"><div align="center">Time</div></th>-->
  <!--    <th width="438" scope="col" bgcolor="#3fcccc"><div align="center">Schedule</div></th>-->
  <!--  </tr>-->
  <!--  <tr>-->
  <!--    <td><div align="center">7:30 - 8:30</div></td>-->
  <!--    <td><div align="center">Breakfast &nbsp; <i>South Poolside</i></div></td>-->
  <!--  </tr>-->
  <!--  <tr>-->
  <!--    <td><div align="center">8:30 - 9:30</div></td>-->
  <!--    <td><div align="left">Paper Award Announcement<br><b><a href="{{ site.baseurl }}/keynotes.html#session2">Keynote: Kai Yu</a></b> &nbsp; <i>International Ballroom</i></div></td>-->
  <!--  </tr>-->
  <!--  <tr>-->
  <!--    <td><div align="center">9:30 - 10:00</div></td>-->
  <!--    <td><div align="center">Coffee break</div></td>    </tr>-->
  <!--  <tr>-->
  <!--    <td><div align="center">10:00 - 12:00</div></td>-->
  <!--    <td><div align="left"><b><a href="{{ site.baseurl }}/oral_sessions.html#session1">Oral Session 1</a></b> &nbsp; <i>International Ballroom</i></div>-->
  <!--  <UL>-->
  <!--      <LI>Computational Complexity of Linear Large Margin Classification With Ramp Loss-->
  <!--      <LI>A la Carte -- Learning Fast Kernels-->
  <!--      <LI>A Scalable Algorithm for Structured Kernel Feature Selection-->
  <!--      <LI>Learning where to Sample in Structured Prediction-->
  <!--  </UL>-->
  <!--  </td>-->
  <!--  <tr>-->
  <!--    <td><div align="center">12:00 - 14:00</div></td>-->
  <!--    <td><div align="center">Lunch on your own</div></td>-->
  <!--  <tr>-->
  <!--    <td><div align="center">14:00 - 16:00</div></td>-->
  <!--    <td><div align="left"><b><a href="{{ site.baseurl }}/oral_sessions.html#session2">Oral Session 2</a></b> &nbsp; <i>International Ballroom</i></div>-->
  <!--  <UL>-->
  <!--      <LI>Tradeoffs for Space, Time, Data and Risk in Unsupervised Learning-->
  <!--      <LI>Constant Step Size Least-Mean-Squares: Bias-Variance Trade-offs and Optimal Sampling Distributions-->
  <!--      <LI>Sparsistency of l_1-Regularized M-Estimators-->
  <!--      <LI>Two-stage sampled learning theory on distributions-->
  <!--  </UL>-->
  <!--  </td>-->
  <!--  <tr>-->
  <!--    <td><div align="center">16:00 - 16:30</div></td>-->
  <!--    <td><div align="center">Coffee break</div></td>-->
  <!--  <tr>-->
  <!--    <td><div align="center">16:30 - 18:30</div></td>-->
  <!--    <td><div align="left"><b><a href="{{ site.baseurl }}/oral_sessions.html#session3">Oral Session 3</a></b> &nbsp; <i>International Ballroom</i></div>-->
  <!--  <UL>-->
  <!--      <LI>Generalized Linear Models for Aggregated Data-->
  <!--      <LI>Efficient Estimation of Mutual Information for Strongly Dependent Variables-->
  <!--      <LI>Understanding and Evaluating Sparse Linear Discriminant Analysis-->
  <!--      <LI>Back to the Past: Source Identification in Diffusion Networks-->
  <!--  </UL>-->
  <!--  </td>-->
  <!--  <tr>-->
  <!--    <td><div align="center">18:30 - 19:30</div></td>-->
  <!--    <td><div align="center">Dinner on your own</div></td>-->
  <!--  <tr>-->
  <!--    <td><div align="center">19:30 - 22:00</div></td>-->
  <!--    <td><div align="left"><b><a href="{{ site.baseurl }}/poster_sessions.html#session1">Poster Session 1</a></b> &nbsp; <i>Pavilion</i></div></td>-->
  <!--  </tr>-->
  <!--</table>-->

<br>





</div>

<!--- XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX -->
